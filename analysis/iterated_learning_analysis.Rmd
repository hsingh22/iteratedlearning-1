---
title: "iterated_learning"
author: "Maddie Meyers, Dan Yurovsky"
date: "7/19/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(tidyverse)
library(png)
library(grid)
library(xtable)
library(feather)
library(irr)
library(tidyboot)
library(directlabels)
library(lme4)
library(broom)
library(acss)
library(devtools)
library(reshape2)

theme_set(theme_classic(base_size = 10))
```

## Setup

Loading functions -- OLD 
```{r load csv}
data2 <- read_csv("../data/anonymized_data.csv")
kidData<-read_csv("iteratedstudyresults.csv")
practice_data <- matrix(sample(0:1, 64, replace=TRUE), nrow=8, ncol=8)

#filters out people who didn't complete 10 trials
data <- data2 %>%
#data<-kidData %>%
 arrange(sub_id, trialDisplay) %>%
  group_by(sub_id) %>%
  mutate(n = n()) %>%
  filter(n >= 12 & condition != "test" & sub_id != 0) %>%
 # filter(condition == "pilotkid" & sub_id != "Xx" & sub_id != "sdgd" & sub_id != 1) %>%
  select(-n) %>%
  ungroup() %>%
  filter(trialCount < 14)
```
format data -- OLD
```{r}
spread_data <- data %>%
  gather(row, value, -sub_id, -age, -condition, -generation, -date, -time, -trialDisplay, -trialCount, -comments)%>%
  arrange(sub_id, trialDisplay) %>%
  separate(row, c("type","row", "col")) %>%
  unite(ty_col, type, col) %>%
  spread(ty_col, value) %>%
  filter(is.na(row)==F)
```
--Format data OLD
```{r formats data}
calculate_data <- data %>%
  gather(row, value,-sub_id:-trialDisplay)%>%
  arrange(sub_id, trialDisplay) %>%
  separate(row, c("type","row", "col")) %>%
  spread(type,value) %>%
  mutate(input = as.numeric(input), target = as.numeric(target),
         row = as.numeric(row), column = as.numeric(col)) %>%
  mutate(accuracy = input == target,
         sub_id = as.character(sub_id)) 
```


## Read in Data from Google Sheet (Pilot)
```{r read in data from google sheet}
data_sheet <- gs_ls() %>%
  filter(sheet_title == "Kid Generations") %>%
  pull(sheet_key) %>%
  gs_key() %>%
  gs_read(ws = "Sheet1") %>%
  filter(seed == 1 & condition == "adult_baseline_pilot") #filter to just this pilot seed data 
```

## Read in Adult Baseline Data (saved as .csv taken from Google Sheet, includes only full chains)
```{r read in data}
adult_baseline <- read_csv("../data/adult_baseline.csv") %>%
  select(-sum_timeUsed)

```


## Format Data for Display & Grid Analysis - New
```{r}
data <- adult_baseline %>% #puts each trial and either target or display in a separate row
  select(-available_onload, -available_accepted, -sub_age) %>%
  gather(display, array, -unique_id, -parent_id, -child_id, -sub_id, -generation, -seed, -condition, -date, -time, -trial1Count, -time1Used, -trial1Display, -trial2Count, -time2Used, -trial2Display, -trial4Count, -trial4Display, -time4Used, -trial5Count, -trial5Display, -time5Used, -trial6Count, -trial6Display, -time6Used, -trial7Count, -trial7Display, -time7Used, -trial8Count, -trial8Display, -time8Used, -trial9Count, -trial9Display, -time9Used) %>%
  arrange(sub_id) %>%
  unique() %>%
  separate(display, c("type", "trialCountArray"), -6) %>%
  separate(trialCountArray, c("trialCount", "arrayCount"), 1) %>%
  select(-arrayCount, -trial1Count, -trial2Count, -trial4Count, -trial5Count, -trial6Count, -trial7Count, -trial8Count, -trial9Count) %>%
  gather(trialDisplay, display, -unique_id, -parent_id, -child_id, -sub_id, -generation, -seed, -condition, -date, -time, -time1Used, -time2Used, -time4Used, -time5Used, -time6Used, -time7Used,  -time8Used,-time9Used, -type, -trialCount, -array) %>%
  separate(trialDisplay, c("type2", "tmp"), -7) %>%
  select(-tmp) %>%
  separate(type2, c("tmp", "trialCount2"), -1) %>%
  select(-tmp) %>%
  filter(trialCount2 == trialCount) %>%
  select(-trialCount2, trialDisplay = display) %>%
  gather(trialTime, timeUsed, -unique_id, -parent_id, -child_id, -sub_id, -generation, -seed, -condition, -date, -time, -type, -trialCount, -trialDisplay, -array) %>%
  separate(trialTime, c("tmp", "trialCount3"), -5) %>%
  separate(trialCount3, c("trialCount3", "tmp2"), 1) %>%
  select(-tmp, -tmp2) %>%
  filter(trialCount == trialCount3) %>%
  select(unique_id, parent_id, child_id, sub_id, generation, seed, condition, date, time, trialCount, trialDisplay, timeUsed, type, array) %>%
  spread(type, array) %>%
  separate(data, c("input_0_0", "input_0_1", "input_0_2", "input_0_3", "input_0_4", "input_0_5", "input_0_6", "input_0_7", "input_1_0", "input_1_1", "input_1_2", "input_1_3", "input_1_4", "input_1_5", "input_1_6", "input_1_7", "input_2_0", "input_2_1", "input_2_2", "input_2_3", "input_2_4", "input_2_5", "input_2_6", "input_2_7", "input_3_0", "input_3_1", "input_3_2", "input_3_3", "input_3_4", "input_3_5", "input_3_6", "input_3_7", "input_4_0", "input_4_1", "input_4_2", "input_4_3", "input_4_4", "input_4_5", "input_4_6", "input_4_7", "input_5_0", "input_5_1", "input_5_2", "input_5_3", "input_5_4", "input_5_5", "input_5_6", "input_5_7", "input_6_0", "input_6_1", "input_6_2", "input_6_3", "input_6_4", "input_6_5", "input_6_6", "input_6_7", "input_7_0", "input_7_1", "input_7_2", "input_7_3", "input_7_4", "input_7_5", "input_7_6", "input_7_7"), sep = " ") %>%
    separate(target, c("target_0_0", "target_0_1", "target_0_2", "target_0_3", "target_0_4", "target_0_5", "target_0_6", "target_0_7", "target_1_0", "target_1_1", "target_1_2", "target_1_3", "target_1_4", "target_1_5", "target_1_6", "target_1_7", "target_2_0", "target_2_1", "target_2_2", "target_2_3", "target_2_4", "target_2_5", "target_2_6", "target_2_7", "target_3_0", "target_3_1", "target_3_2", "target_3_3", "target_3_4", "target_3_5", "target_3_6", "target_3_7", "target_4_0", "target_4_1", "target_4_2", "target_4_3", "target_4_4", "target_4_5", "target_4_6", "target_4_7", "target_5_0", "target_5_1", "target_5_2", "target_5_3", "target_5_4", "target_5_5", "target_5_6", "target_5_7", "target_6_0", "target_6_1", "target_6_2", "target_6_3", "target_6_4", "target_6_5", "target_6_6", "target_6_7", "target_7_0", "target_7_1", "target_7_2", "target_7_3", "target_7_4", "target_7_5", "target_7_6", "target_7_7"), sep = " ") 

calculate_data <-data %>%
  gather(row, value,-unique_id:-timeUsed)%>%
  arrange(sub_id, trialDisplay) %>%
  separate(row, c("type","row", "col")) %>%
  spread(type,value) %>%
  mutate(input = as.numeric(input), target = as.numeric(target),
         row = as.numeric(row), column = as.numeric(col)) %>%
  mutate(accuracy = input == target,
         sub_id = as.character(sub_id)) %>%
  arrange(seed, generation) 


spread_data <- data %>%
  gather(row, value, -unique_id, -parent_id, -child_id, -sub_id, -condition, -generation, -seed, -date, -time, -trialDisplay, -trialCount, -timeUsed)%>%
  arrange(sub_id, trialDisplay) %>%
  separate(row, c("type","row", "col")) %>%
  unite(ty_col, type, col) %>%
  spread(ty_col, value) %>%
  filter(is.na(row)==F)
```

## Descriptive
Displays the actual grids that people made; printed them and saved
```{r plot_grids}
pdf("trial_data_adults_s14.pdf", width = 10, height = 10)
s14_data %>%
  bind_rows(select(s14_data, generation, trialDisplay, row, col, input)) %>%
  mutate(input = factor(input), generation = factor(generation, levels = unique(.$generation))) %>%
  mutate(row = 7 - row) %>%
  ggplot(aes(x = col, y = row, fill = input)) +
  facet_grid(trialDisplay ~ generation) +
  geom_tile(color = "black") +
  scale_fill_manual(values = c("0" = "white", "1" = "black"), guide = F) 
dev.off()
```

## Analysis

## Time Used per trial
How much time did people use on each trial? did this go down over generations?
```{r time used data}
time_used <- data %>%
  filter(generation != 0)

#time used and generation no are not related (not less time used as gen increases); overall trend down but two outliers 
ggplot(time_used %>%  group_by(generation) %>%
  mutate(totalTime = sum(timeUsed)), aes(x=generation, y=totalTime)) +geom_point() +geom_smooth(method="lm")

#people don't vary on time used by trial display, except use more for real vs. training trials
ggplot(time_used %>%  group_by(trialDisplay) %>%
  mutate(totalTime = sum(timeUsed)), aes(x=trialDisplay, y=totalTime)) +geom_point() +geom_smooth(method="lm")

#people use less time per trial as trial # increases (after practice)  
ggplot(time_used %>%  group_by(trialCount) %>%
  mutate(totalTime = sum(timeUsed)), aes(x=trialCount, y=totalTime)) +geom_point()
```

## Percent Accuracy 
Percent accuracies calculated by %/10 targets placed correctly 
```{r accuracy}
trial_data <- calculate_data %>%
  filter(generation != 0, seed != 20) %>%
  filter(target == 1) 

#no practice effects overall across trial order 
ggplot(trial_data %>% group_by(trialCount, sub_id) %>% summarise(accuracy = mean(accuracy)) %>% tidyboot_mean(accuracy), aes(x = trialCount, y = empirical_stat, 
                       ymin = ci_lower, ymax = ci_upper)) + 
  geom_pointrange()+ylab("average percent accuracy")

#people found trial 6 to be easier than the other trials overall 
ggplot(trial_data %>% group_by(trialDisplay, sub_id) %>% summarise(accuracy = mean(accuracy)) %>% tidyboot_mean(accuracy), aes(x = trialDisplay, y = empirical_stat, 
                       ymin = ci_lower, ymax = ci_upper)) + 
  geom_pointrange()+ylab("average percent accuracy")

#percent accuracy increases over gens 1-4 and asymptotes
ggplot(trial_data %>% filter(trialCount > 3) %>% group_by(generation, sub_id) %>% summarise(accuracy = mean(accuracy)) %>% tidyboot_mean(accuracy), aes(x = generation, y = empirical_stat, 
                       ymin = ci_lower, ymax = ci_upper)) + 
  geom_pointrange()+ylab("average percent accuracy") 

#shows percent accuracy over generation by seed, see variation 
ggplot(trial_data %>% filter(trialCount > 3) %>% group_by(generation,  seed) %>% summarise(accuracy = mean(accuracy)), aes(x = generation, y = accuracy, color=seed)) + 
  geom_point()+ylab("average percent accuracy") +geom_smooth(method = "lm")

#seeds are diverse but generally constant once you take out seed 20 which was an outlier
ggplot(trial_data %>% group_by(seed, sub_id) %>% summarise(accuracy = mean(accuracy)) %>% tidyboot_mean(accuracy), aes(x = seed, y = empirical_stat, 
                       ymin = ci_lower, ymax = ci_upper)) + 
  geom_pointrange() +geom_smooth(method = "lm")+ylab("average percent accuracy")
```

## Gauvrit Analyses

##Functions
Block Decomposition Method for Algorithmic Complexity 
```{r}
bdm_function = function(m){
  x = rep("x", nrow(m)/8)
  k=1
  q=1
  for(i in 1:(nrow(m)/8)){
    df = m[q:(q+7), 5:12] #CHANGE IF CHANGE INPUT COLUMNS
    data.matrix(df)
    x[k] = bdm(df)
    k = k +1
    q=q+8
  }
  return(x) 
}
```

## Chunking
```{r}
nPart_function = function(m){
  x = rep("x", nrow(m)/8)
  k=1
  q=1
  for(i in 1:(nrow(m)/8)){
    df = m[q:(q+7), 5:12] #CHANGE IF CHANGE INPUT COLUMNS
    data.matrix(df)
    x[k] = nPart(df)
    k = k +1
    q=q+8
  }
  return(x) 
}
```

## Edge Length
```{r}
edge_function = function(m){
  x = rep("x", nrow(m)/8)
  k=1
  q=1
  for(i in 1:(nrow(m)/8)){
    df = m[q:(q+7), 5:12] #CHANGE IF CHANGE INPUT COLUMNS
    data.matrix(df)
    x[k] = edge(df)
    k = k +1
    q=q+8
  }
  return(x) 
}
```

## Analysis

```{r}
bdm_data <- spread_data %>%
  filter(trialCount > 3, generation != 0, seed != 20) %>%
  select(sub_id, generation,trialDisplay, row, input_0:input_7) %>%
  mutate(input_7 = as.numeric(input_7),
         input_6 = as.numeric(input_6),
         input_5 = as.numeric(input_5),
         input_4 = as.numeric(input_4),
         input_3 = as.numeric(input_3),
         input_2 = as.numeric(input_2),
         input_1 = as.numeric(input_1),
         input_0 = as.numeric(input_0)) 

target_data <- spread_data %>%
  filter(trialDisplay != 0 & trialDisplay != 0.5 & generation == 0 & seed !=20)  %>%
  select(sub_id, generation,trialDisplay, row, input_0:input_7) %>%
  mutate(sub_id = 0) %>%
  mutate(target_0 = as.numeric(input_7),
         target_1 = as.numeric(input_6),
         target_2 = as.numeric(input_5),
         target_3 = as.numeric(input_4),
         target_4 = as.numeric(input_3),
         target_5 = as.numeric(input_2),
         target_6 = as.numeric(input_1),
         target_7 = as.numeric(input_0)) %>%
  select(-(input_0:input_7)) %>%
  arrange(trialDisplay,row) %>%
  unique()
 
target_store <- data.frame(bdm = bdm_function(target_data),
                           chunking = nPart_function(target_data),
                           edge = edge_function(target_data)) 
bdm_store <- data.frame(bdm = bdm_function(bdm_data),
                        chunking = nPart_function(bdm_data),
                        edge = edge_function(bdm_data))

bind_targets <- target_data %>%
  group_by(sub_id,trialDisplay, generation) %>%
  summarise(.) %>%
  bind_cols(target_store, .)

bind_data <- bdm_data %>%
  group_by(sub_id,trialDisplay, generation) %>%
  summarise(.) %>%
  bind_cols(bdm_store, .) %>%
  bind_rows(. , bind_targets) %>%
  mutate(bdm = as.numeric(bdm),
         chunking = as.numeric(chunking),
         edge = as.numeric(edge)) %>%
  group_by(sub_id,trialDisplay, generation)%>%
  summarise(bdm_mean = mean(bdm),
            chunking_mean = mean(chunking),
            edge_mean = mean(edge)) 

```

```{r graphs}
#algorithmic complexity decreases linearly by generation; same amount decrease as Kempe
ggplot(bind_data %>%group_by(generation) %>% tidyboot_mean(bdm_mean), aes(x = generation, y = empirical_stat, 
                       ymin = ci_lower, ymax = ci_upper)) + 
  geom_pointrange()+geom_line()+ylab("algorithmic complexity")+ggtitle("algorithmic complexity over generations")

#seems to be variation by trial display but same general trend
ggplot(bind_data %>%group_by(generation, trialDisplay) %>% tidyboot_mean(bdm_mean), aes(x = generation, y = empirical_stat, 
                       ymin = ci_lower, ymax = ci_upper)) + 
  geom_pointrange()+geom_smooth()+ylab("algorithmic complexity")+facet_wrap(~trialDisplay)+ggtitle("algoritmic complexity over generations by trial display")

#number of chunks decreases linearly by generation
ggplot(bind_data %>% group_by(generation) %>% tidyboot_mean(chunking_mean), aes(x = generation, y = empirical_stat, 
                       ymin = ci_lower, ymax = ci_upper)) + 
  geom_pointrange()+geom_line()+ylab("number of chunks")+ggtitle("chunking over generations")

#edge length decreases linearly by generation
ggplot(bind_data %>% group_by(generation) %>% tidyboot_mean(edge_mean), aes(x = generation, y = empirical_stat, 
                       ymin = ci_lower, ymax = ci_upper)) + 
  geom_pointrange()+geom_line()+ylab("edge length")+ggtitle("edge length over generations")

```


Block Decomposition Method for Algorithmic Complexity 
```{r}
bdm_seed_function = function(m){
  x = rep("x", nrow(m)/8)
  k=1
  q=1
  for(i in 1:(nrow(m)/8)){
    df = m[q:(q+7), 6:13] #CHANGE IF CHANGE INPUT COLUMNS
    data.matrix(df)
    x[k] = bdm(df)
    k = k +1
    q=q+8
  }
  return(x) 
}
```

## Chunking
```{r}
nPart_seed_function = function(m){
  x = rep("x", nrow(m)/8)
  k=1
  q=1
  for(i in 1:(nrow(m)/8)){
    df = m[q:(q+7), 6:13] #CHANGE IF CHANGE INPUT COLUMNS
    data.matrix(df)
    x[k] = nPart(df)
    k = k +1
    q=q+8
  }
  return(x) 
}
```

## Edge Length
```{r}
edge_seed_function = function(m){
  x = rep("x", nrow(m)/8)
  k=1
  q=1
  for(i in 1:(nrow(m)/8)){
    df = m[q:(q+7), 6:13] #CHANGE IF CHANGE INPUT COLUMNS
    data.matrix(df)
    x[k] = edge(df)
    k = k +1
    q=q+8
  }
  return(x) 
}
```

```{r}
bdm_seed_data <- spread_data %>%
  filter(trialCount > 3, generation != 0, seed != 20) %>%
  select(sub_id=unique_id, generation,seed,trialDisplay, row, input_0:input_7) %>%
  mutate(input_7 = as.numeric(input_7),
         input_6 = as.numeric(input_6),
         input_5 = as.numeric(input_5),
         input_4 = as.numeric(input_4),
         input_3 = as.numeric(input_3),
         input_2 = as.numeric(input_2),
         input_1 = as.numeric(input_1),
         input_0 = as.numeric(input_0)) %>%
  arrange(trialDisplay, sub_id)

target_seed_data <- spread_data %>%
  filter(trialDisplay != 0 & trialDisplay != 0.5 & generation == 0 & seed !=20)  %>%
  select(sub_id = unique_id, generation,seed,trialDisplay, row, input_0:input_7) %>%
  mutate(target_0 = as.numeric(input_7),
         target_1 = as.numeric(input_6),
         target_2 = as.numeric(input_5),
         target_3 = as.numeric(input_4),
         target_4 = as.numeric(input_3),
         target_5 = as.numeric(input_2),
         target_6 = as.numeric(input_1),
         target_7 = as.numeric(input_0)) %>%
  select(-(input_0:input_7)) %>%
  arrange(trialDisplay,sub_id) %>%
  unique()
 
target_seed_store <- data.frame(bdm = bdm_seed_function(target_seed_data),
                           chunking = nPart_seed_function(target_seed_data),
                           edge = edge_seed_function(target_seed_data)) 
bdm_seed_store <- data.frame(bdm = bdm_seed_function(bdm_seed_data),
                        chunking = nPart_seed_function(bdm_seed_data),
                        edge = edge_seed_function(bdm_seed_data))

bind_seed_targets <- target_seed_data %>%
  group_by(trialDisplay,sub_id,generation,seed) %>%
  summarise(.) %>%
  bind_cols(target_seed_store, .)

bind_seed_data <- bdm_seed_data %>%
  group_by(trialDisplay, sub_id, generation,seed) %>%
  summarise(.) %>%
  bind_cols(bdm_seed_store, .) %>%
  bind_rows(. , bind_seed_targets) %>%
  mutate(bdm = as.numeric(bdm),
         chunking = as.numeric(chunking),
         edge = as.numeric(edge)) %>%
  group_by(sub_id,trialDisplay, generation,seed)%>%
  summarise(bdm_mean = mean(bdm),
            chunking_mean = mean(chunking),
            edge_mean = mean(edge)) 

```

```{r graphs}
#shows complexity by seed, see variation but same general trend across seeds 
ggplot(bind_seed_data %>%group_by(generation, seed) %>% tidyboot_mean(bdm_mean), aes(x = generation, y = empirical_stat,  
                       ymin = ci_lower, ymax = ci_upper)) + 
  geom_pointrange()+geom_line()+ylab("algorithmic complexity")+facet_wrap(~seed)+scale_y_continuous(limits = c(160,250))+ggtitle("algorithmic complexity over generations by distinct chain #")

#these trends seem to be more dramatic here! There's one chain that doesn't decrease, but some very dramatic
ggplot(bind_seed_data %>% group_by(generation,seed) %>% tidyboot_mean(chunking_mean), aes(x = generation, y = empirical_stat, 
                       ymin = ci_lower, ymax = ci_upper)) + 
  geom_pointrange()+geom_line()+ylab("number of chunks")+facet_wrap(~seed)+ggtitle("chunking over generations by distinct chain #")

#trends are same
ggplot(bind_seed_data %>% group_by(generation,seed) %>% tidyboot_mean(edge_mean), aes(x = generation, y = empirical_stat, 
                       ymin = ci_lower, ymax = ci_upper)) + 
  geom_pointrange()+geom_line()+ylab("edge length")+facet_wrap(~seed)+ggtitle("edge length over generations by distinct chain #")
```

## Identifiability
Kempe et al defined this as the proportion of within-chain similarity / (within-chain)+(across-chain similarity). We will define "similarity" as the percent of same cells highlighted (like we did for % accuracy between target/input, but just with input of gen 1 seed 1 compared to input of gen 1 seed 2). 
